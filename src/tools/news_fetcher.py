"""
ãƒ‹ãƒ¥ãƒ¼ã‚¹å–å¾—ãƒ˜ãƒ«ãƒ‘ãƒ¼

Claude Codeã¨é€£æºã—ã¦WebSearchã§ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’å–å¾—ã—ã€DBã«ä¿å­˜ã—ã¾ã™
"""

import sys
import os
import io
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

from src.analysis.news_collector import NewsCollector
from src.data.advanced_database import AdvancedDatabase
from datetime import datetime
from pathlib import Path
import argparse


class NewsFetcher:
    """ãƒ‹ãƒ¥ãƒ¼ã‚¹å–å¾—ãƒ»ä¿å­˜ã‚·ã‚¹ãƒ†ãƒ """

    def __init__(self):
        self.collector = NewsCollector()
        self.db = AdvancedDatabase()

    def request_news_search(self, symbol: str, coin_name: str = None):
        """
        Claude Codeã«å¯¾ã—ã¦ãƒ‹ãƒ¥ãƒ¼ã‚¹æ¤œç´¢ã‚’ãƒªã‚¯ã‚¨ã‚¹ãƒˆ

        ã“ã®ãƒ¡ã‚½ãƒƒãƒ‰ã¯ã€Claude Codeã«æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’æç¤ºã—ã¾ã™ã€‚
        Claude CodeãŒWebSearchã‚’å®Ÿè¡Œã—ãŸå¾Œã€çµæœã‚’parse_and_save_news()ã«æ¸¡ã—ã¦ãã ã•ã„ã€‚
        """
        if not coin_name:
            coin_name = self._get_coin_name(symbol)

        query = f"{coin_name} {symbol} ä»®æƒ³é€šè²¨ æœ€æ–°ãƒ‹ãƒ¥ãƒ¼ã‚¹ 2025"

        print("="*80)
        print("ğŸ“° ãƒ‹ãƒ¥ãƒ¼ã‚¹å–å¾—ãƒªã‚¯ã‚¨ã‚¹ãƒˆ")
        print("="*80)
        print()
        print(f"**éŠ˜æŸ„**: {symbol} ({coin_name})")
        print(f"**æ¤œç´¢ã‚¯ã‚¨ãƒª**: {query}")
        print()
        print("="*80)
        print("æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
        print("="*80)
        print()
        print("Claude Codeã«ã“ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä¼ãˆã¦ãã ã•ã„:")
        print()
        print(f'ã€Œ{query}ã€ã§WebSearchã‚’å®Ÿè¡Œã—ã¦ã€')
        print(f'çµæœã‚’ news_fetcher.parse_and_save_news() ã«æ¸¡ã—ã¦ãã ã•ã„')
        print()
        print("ã¾ãŸã¯ã€ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„:")
        print()
        print(f'  python src/tools/news_fetcher.py {symbol} --interactive')
        print()
        print("="*80)

        return query

    def parse_and_save_news(self, symbol: str, search_results: list, coin_name: str = None):
        """
        WebSearchã®çµæœã‚’è§£æã—ã¦DBã«ä¿å­˜

        Args:
            symbol: éŠ˜æŸ„ã‚·ãƒ³ãƒœãƒ«
            search_results: WebSearchã®çµæœãƒªã‚¹ãƒˆ
            coin_name: éŠ˜æŸ„åï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰

        Returns:
            ä¿å­˜ä»¶æ•°
        """
        if not coin_name:
            coin_name = self._get_coin_name(symbol)

        print("="*80)
        print(f"ğŸ“° {symbol} ãƒ‹ãƒ¥ãƒ¼ã‚¹ä¿å­˜ä¸­...")
        print("="*80)
        print()

        news_data = []
        for result in search_results:
            # WebSearchã®çµæœã‚’æ¨™æº–ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«å¤‰æ›
            news_item = {
                'title': result.get('title', ''),
                'content': result.get('description', result.get('snippet', '')),
                'url': result.get('url', ''),
                'source': self._extract_domain(result.get('url', '')),
                'published_date': result.get('date', datetime.now().isoformat()),
                'sentiment': self._simple_sentiment_analysis(
                    result.get('title', '') + ' ' + result.get('description', '')
                ),
                'importance_score': 0.7,  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
                'impact_score': 0.6,      # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
                'keywords': [symbol, coin_name],
            }
            news_data.append(news_item)

        # DBã«ä¿å­˜
        saved_count = self.collector.collect_news_for_coin(symbol, coin_name, news_data)

        print()
        print(f"âœ… {saved_count}ä»¶ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’ä¿å­˜ã—ã¾ã—ãŸ")
        print()

        # Markdownå½¢å¼ã§ã‚‚ä¿å­˜
        self._save_as_markdown(symbol, news_data)

        return saved_count

    def save_manual_news(self, symbol: str, title: str, content: str, url: str = "", source: str = "Manual"):
        """
        æ‰‹å‹•ã§ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’è¿½åŠ 

        Args:
            symbol: éŠ˜æŸ„ã‚·ãƒ³ãƒœãƒ«
            title: ã‚¿ã‚¤ãƒˆãƒ«
            content: æœ¬æ–‡
            url: URLï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            source: å‡ºå…¸ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        """
        coin_name = self._get_coin_name(symbol)

        news_data = [{
            'title': title,
            'content': content,
            'url': url,
            'source': source,
            'published_date': datetime.now().isoformat(),
            'sentiment': self._simple_sentiment_analysis(title + ' ' + content),
            'importance_score': 0.7,
            'impact_score': 0.6,
            'keywords': [symbol, coin_name],
        }]

        saved_count = self.collector.collect_news_for_coin(symbol, coin_name, news_data)

        if saved_count > 0:
            print(f"âœ… ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’ä¿å­˜ã—ã¾ã—ãŸ")
            self._save_as_markdown(symbol, news_data)
        else:
            print(f"âŒ ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ")

        return saved_count

    def _get_coin_name(self, symbol: str) -> str:
        """éŠ˜æŸ„ã‚·ãƒ³ãƒœãƒ«ã‹ã‚‰éŠ˜æŸ„åã‚’å–å¾—"""
        coin_names = {
            'BTC': 'Bitcoin',
            'ETH': 'Ethereum',
            'XRP': 'Ripple',
            'DOGE': 'Dogecoin',
            'SHIB': 'Shiba Inu',
            'ADA': 'Cardano',
            'SOL': 'Solana',
            'MATIC': 'Polygon',
        }
        return coin_names.get(symbol.upper(), symbol)

    def _extract_domain(self, url: str) -> str:
        """URLã‹ã‚‰ãƒ‰ãƒ¡ã‚¤ãƒ³åã‚’æŠ½å‡º"""
        if not url:
            return "Unknown"
        try:
            from urllib.parse import urlparse
            domain = urlparse(url).netloc
            return domain.replace('www.', '')
        except:
            return "Unknown"

    def _simple_sentiment_analysis(self, text: str) -> str:
        """ç°¡æ˜“çš„ãªã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆåˆ†æ"""
        text = text.lower()

        positive_words = ['ä¸Šæ˜‡', 'æ€¥é¨°', 'é«˜å€¤', 'å¥½èª¿', 'æœŸå¾…', 'æˆé•·', 'æˆåŠŸ', 'æ‰¿èª', 'ææº', 'æ¡ç”¨']
        negative_words = ['ä¸‹è½', 'æš´è½', 'å®‰å€¤', 'ä¸èª¿', 'æ‡¸å¿µ', 'è¦åˆ¶', 'å¤±æ•—', 'ãƒãƒƒã‚­ãƒ³ã‚°', 'è©æ¬º']

        positive_count = sum(1 for word in positive_words if word in text)
        negative_count = sum(1 for word in negative_words if word in text)

        if positive_count > negative_count:
            return 'positive' if positive_count - negative_count >= 2 else 'positive'
        elif negative_count > positive_count:
            return 'negative' if negative_count - positive_count >= 2 else 'negative'
        else:
            return 'neutral'

    def _save_as_markdown(self, symbol: str, news_data: list):
        """ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’Markdownå½¢å¼ã§ä¿å­˜"""
        news_dir = Path('data/news') / symbol
        news_dir.mkdir(parents=True, exist_ok=True)

        sentiment_map = {
            'positive': 'â†—ï¸ ãƒã‚¸ãƒ†ã‚£ãƒ–',
            'negative': 'â†˜ï¸ ãƒã‚¬ãƒ†ã‚£ãƒ–',
            'neutral': 'â¡ï¸ ä¸­ç«‹',
        }

        for news in news_data:
            # ãƒ•ã‚¡ã‚¤ãƒ«åä½œæˆ
            pub_date = news.get('published_date', datetime.now().isoformat())
            try:
                dt = datetime.fromisoformat(pub_date.replace('Z', '+00:00'))
                date_str = dt.strftime('%Y-%m-%d_%H-%M-%S')
            except:
                date_str = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')

            # ã‚¿ã‚¤ãƒˆãƒ«ã‹ã‚‰å®‰å…¨ãªãƒ•ã‚¡ã‚¤ãƒ«åã‚’ä½œæˆ
            safe_title = "".join(c for c in news.get('title', 'news')[:30] if c.isalnum() or c in (' ', '_')).strip()
            filename = f"{date_str}_{safe_title}.md"
            filepath = news_dir / filename

            # æ—¢ã«å­˜åœ¨ã™ã‚‹å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
            if filepath.exists():
                continue

            # Markdownä½œæˆ
            md_content = f"""# {news.get('title', 'ã‚¿ã‚¤ãƒˆãƒ«ãªã—')}

**å‡ºå…¸**: {news.get('source', 'Unknown')}
**å…¬é–‹æ—¥**: {pub_date[:19]}
**URL**: {news.get('url', 'N/A')}

---

## ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆ

{sentiment_map.get(news.get('sentiment', 'neutral'), 'â¡ï¸ ä¸­ç«‹')}

**ã‚¹ã‚³ã‚¢è©³ç´°**:
- é‡è¦åº¦: {news.get('importance_score', 0.5):.3f}
- å½±éŸ¿åŠ›: {news.get('impact_score', 0.5):.3f}

---

## æœ¬æ–‡

{news.get('content', 'ï¼ˆæœ¬æ–‡ãªã—ï¼‰')}

---

**ä¿å­˜æ—¥æ™‚**: {datetime.now().isoformat()}
"""

            # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(md_content)

    def close(self):
        """ãƒªã‚½ãƒ¼ã‚¹ã‚’ã‚¯ãƒ­ãƒ¼ã‚º"""
        self.collector.close()
        self.db.close()


def main():
    parser = argparse.ArgumentParser(
        description='ãƒ‹ãƒ¥ãƒ¼ã‚¹å–å¾—ãƒ˜ãƒ«ãƒ‘ãƒ¼',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ä¾‹:
  # ãƒ‹ãƒ¥ãƒ¼ã‚¹æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’è¡¨ç¤º
  python src/tools/news_fetcher.py BTC

  # æ‰‹å‹•ã§ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’è¿½åŠ 
  python src/tools/news_fetcher.py BTC --add-manual \\
    --title "ãƒ“ãƒƒãƒˆã‚³ã‚¤ãƒ³ãŒæœ€é«˜å€¤æ›´æ–°" \\
    --content "BTCãŒ10ä¸‡ãƒ‰ãƒ«ã‚’çªç ´ã—ã¾ã—ãŸ" \\
    --url "https://example.com/btc-news"
        """
    )

    parser.add_argument('symbol', help='éŠ˜æŸ„ã‚·ãƒ³ãƒœãƒ«ï¼ˆä¾‹: BTC, ETHï¼‰')
    parser.add_argument('--add-manual', action='store_true',
                       help='æ‰‹å‹•ã§ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’è¿½åŠ ')
    parser.add_argument('--title', help='ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚¿ã‚¤ãƒˆãƒ«')
    parser.add_argument('--content', help='ãƒ‹ãƒ¥ãƒ¼ã‚¹æœ¬æ–‡')
    parser.add_argument('--url', default='', help='URL')
    parser.add_argument('--source', default='Manual', help='å‡ºå…¸')

    args = parser.parse_args()

    fetcher = NewsFetcher()

    try:
        if args.add_manual:
            if not args.title or not args.content:
                print("âŒ ã‚¨ãƒ©ãƒ¼: --title ã¨ --content ã¯å¿…é ˆã§ã™")
                return

            fetcher.save_manual_news(
                args.symbol.upper(),
                args.title,
                args.content,
                args.url,
                args.source
            )
        else:
            # ãƒ‹ãƒ¥ãƒ¼ã‚¹æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’è¡¨ç¤º
            fetcher.request_news_search(args.symbol.upper())

    finally:
        fetcher.close()


if __name__ == '__main__':
    main()
