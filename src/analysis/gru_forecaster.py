"""
GRU-based Cryptocurrency Price Forecaster

Research: "High-Frequency Cryptocurrency Price Forecasting Using Machine Learning Models" (MDPI, 2024)
Achieves MAPE = 0.09%, RMSE = 77.17 (vs ARIMA: MAPE = 2.15%, RMSE = 1,234)

24å€ã®ç²¾åº¦å‘ä¸Šã‚’å®Ÿç¾
"""

import sys
import os
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import pandas as pd
import numpy as np
from sklearn.preprocessing import MinMaxScaler
import warnings
warnings.filterwarnings('ignore')


class GRUModel(nn.Module):
    """GRU Neural Network Model"""

    def __init__(self, input_size=5, hidden_size=50, num_layers=2, dropout=0.2):
        """
        Args:
            input_size: å…¥åŠ›æ¬¡å…ƒï¼ˆä¾‹: open, high, low, close, volume = 5ï¼‰
            hidden_size: éš ã‚Œå±¤ã®æ¬¡å…ƒæ•°
            num_layers: GRUå±¤ã®æ•°
            dropout: ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆç‡ï¼ˆéå­¦ç¿’é˜²æ­¢ï¼‰
        """
        super(GRUModel, self).__init__()

        self.hidden_size = hidden_size
        self.num_layers = num_layers

        # GRU layers
        self.gru = nn.GRU(
            input_size=input_size,
            hidden_size=hidden_size,
            num_layers=num_layers,
            batch_first=True,
            dropout=dropout if num_layers > 1 else 0
        )

        # Output layer
        self.fc = nn.Linear(hidden_size, 1)

    def forward(self, x):
        """
        Forward pass

        Args:
            x: (batch_size, sequence_length, input_size)

        Returns:
            out: (batch_size, 1)
        """
        # GRU forward
        out, _ = self.gru(x)

        # Take the last time step
        out = out[:, -1, :]

        # Fully connected layer
        out = self.fc(out)

        return out


class TimeSeriesDataset(Dataset):
    """æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ"""

    def __init__(self, X, y):
        """
        Args:
            X: (num_samples, sequence_length, input_size)
            y: (num_samples, 1)
        """
        self.X = torch.FloatTensor(X)
        self.y = torch.FloatTensor(y)

    def __len__(self):
        return len(self.X)

    def __getitem__(self, idx):
        return self.X[idx], self.y[idx]


class GRUForecastingEngine:
    """GRUäºˆæ¸¬ã‚¨ãƒ³ã‚¸ãƒ³"""

    def __init__(self, lookback=60, forecast_horizon=7, hidden_size=50, num_layers=2):
        """
        Args:
            lookback: éå»ä½•æ—¥åˆ†ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ã†ã‹ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 60æ—¥ï¼‰
            forecast_horizon: ä½•æ—¥å…ˆã‚’äºˆæ¸¬ã™ã‚‹ã‹ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 7æ—¥ï¼‰
            hidden_size: GRUã®éš ã‚Œå±¤æ¬¡å…ƒ
            num_layers: GRUå±¤ã®æ•°
        """
        self.lookback = lookback
        self.forecast_horizon = forecast_horizon
        self.hidden_size = hidden_size
        self.num_layers = num_layers

        self.model = None
        self.scaler = MinMaxScaler(feature_range=(0, 1))
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

        print(f"ğŸ”§ GRU Forecasting Engine initialized")
        print(f"   Device: {self.device}")
        print(f"   Lookback: {lookback} days")
        print(f"   Forecast horizon: {forecast_horizon} days")

    def prepare_data(self, df: pd.DataFrame, train_ratio=0.8):
        """
        æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã‚’å­¦ç¿’ç”¨ã«å¤‰æ›

        Args:
            df: ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ï¼ˆcolumns: open, high, low, close, volumeï¼‰
            train_ratio: è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®å‰²åˆ

        Returns:
            train_loader, val_loader, test_data
        """
        print("\nğŸ“Š Preparing data...")

        # å¿…è¦ãªã‚«ãƒ©ãƒ ã‚’æŠ½å‡º
        data = df[['open', 'high', 'low', 'close', 'volume']].values

        # æ­£è¦åŒ–ï¼ˆ0-1ã®ç¯„å›²ã«ï¼‰
        data_normalized = self.scaler.fit_transform(data)

        # ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚’ä½œæˆ
        X, y = [], []
        for i in range(len(data_normalized) - self.lookback - self.forecast_horizon + 1):
            # éå»lookbackæ—¥åˆ†ã®ãƒ‡ãƒ¼ã‚¿
            X.append(data_normalized[i:i + self.lookback])

            # forecast_horizonæ—¥å¾Œã®çµ‚å€¤ï¼ˆæ­£è¦åŒ–æ¸ˆã¿ï¼‰
            target_idx = i + self.lookback + self.forecast_horizon - 1
            y.append(data_normalized[target_idx, 3])  # closeä¾¡æ ¼ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã¯3

        X = np.array(X)
        y = np.array(y).reshape(-1, 1)

        print(f"   Total samples: {len(X)}")
        print(f"   Input shape: {X.shape}")
        print(f"   Target shape: {y.shape}")

        # è¨“ç·´/æ¤œè¨¼/ãƒ†ã‚¹ãƒˆåˆ†å‰²
        train_size = int(len(X) * train_ratio)
        val_size = int(len(X) * 0.1)

        X_train, y_train = X[:train_size], y[:train_size]
        X_val, y_val = X[train_size:train_size + val_size], y[train_size:train_size + val_size]
        X_test, y_test = X[train_size + val_size:], y[train_size + val_size:]

        print(f"   Train: {len(X_train)}, Val: {len(X_val)}, Test: {len(X_test)}")

        # DataLoaderã‚’ä½œæˆ
        train_dataset = TimeSeriesDataset(X_train, y_train)
        val_dataset = TimeSeriesDataset(X_val, y_val)

        train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)

        return train_loader, val_loader, (X_test, y_test)

    def train(self, train_loader, val_loader, epochs=100, learning_rate=0.001):
        """
        ãƒ¢ãƒ‡ãƒ«è¨“ç·´

        Args:
            train_loader: è¨“ç·´ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼
            val_loader: æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼
            epochs: ã‚¨ãƒãƒƒã‚¯æ•°
            learning_rate: å­¦ç¿’ç‡
        """
        print(f"\nğŸš€ Training GRU model...")
        print(f"   Epochs: {epochs}")
        print(f"   Learning rate: {learning_rate}")

        # ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–
        input_size = 5  # open, high, low, close, volume
        self.model = GRUModel(
            input_size=input_size,
            hidden_size=self.hidden_size,
            num_layers=self.num_layers
        ).to(self.device)

        # ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ãƒ¼ã¨æå¤±é–¢æ•°
        criterion = nn.MSELoss()
        optimizer = optim.Adam(self.model.parameters(), lr=learning_rate)

        # Early Stoppingç”¨
        best_val_loss = float('inf')
        patience = 10
        patience_counter = 0

        # è¨“ç·´ãƒ«ãƒ¼ãƒ—
        for epoch in range(epochs):
            # è¨“ç·´ãƒ¢ãƒ¼ãƒ‰
            self.model.train()
            train_loss = 0.0

            for X_batch, y_batch in train_loader:
                X_batch = X_batch.to(self.device)
                y_batch = y_batch.to(self.device)

                # Forward pass
                outputs = self.model(X_batch)
                loss = criterion(outputs, y_batch)

                # Backward pass
                optimizer.zero_grad()
                loss.backward()
                optimizer.step()

                train_loss += loss.item()

            train_loss /= len(train_loader)

            # æ¤œè¨¼ãƒ¢ãƒ¼ãƒ‰
            self.model.eval()
            val_loss = 0.0

            with torch.no_grad():
                for X_batch, y_batch in val_loader:
                    X_batch = X_batch.to(self.device)
                    y_batch = y_batch.to(self.device)

                    outputs = self.model(X_batch)
                    loss = criterion(outputs, y_batch)

                    val_loss += loss.item()

            val_loss /= len(val_loader)

            # ã‚¨ãƒãƒƒã‚¯ã”ã¨ã®çµæœè¡¨ç¤º
            if (epoch + 1) % 10 == 0:
                print(f"   Epoch [{epoch + 1}/{epochs}] - Train Loss: {train_loss:.6f}, Val Loss: {val_loss:.6f}")

            # Early Stopping
            if val_loss < best_val_loss:
                best_val_loss = val_loss
                patience_counter = 0
                # æœ€è‰¯ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜
                torch.save(self.model.state_dict(), 'best_gru_model.pth')
            else:
                patience_counter += 1

            if patience_counter >= patience:
                print(f"   Early stopping at epoch {epoch + 1}")
                break

        # æœ€è‰¯ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰
        self.model.load_state_dict(torch.load('best_gru_model.pth', weights_only=True))
        print(f"\nâœ… Training completed! Best val loss: {best_val_loss:.6f}")

    def evaluate(self, test_data):
        """
        ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§è©•ä¾¡

        Args:
            test_data: (X_test, y_test)

        Returns:
            metrics: dict
        """
        print(f"\nğŸ“ˆ Evaluating model...")

        X_test, y_test = test_data

        self.model.eval()
        with torch.no_grad():
            X_test_tensor = torch.FloatTensor(X_test).to(self.device)
            predictions = self.model(X_test_tensor).cpu().numpy()

        # é€†æ­£è¦åŒ–
        # predictionsã¨y_testã‚’å…ƒã®ã‚¹ã‚±ãƒ¼ãƒ«ã«æˆ»ã™
        predictions_denorm = self._denormalize_price(predictions)
        y_test_denorm = self._denormalize_price(y_test)

        # è©•ä¾¡æŒ‡æ¨™
        mse = np.mean((predictions_denorm - y_test_denorm) ** 2)
        rmse = np.sqrt(mse)
        mae = np.mean(np.abs(predictions_denorm - y_test_denorm))
        mape = np.mean(np.abs((predictions_denorm - y_test_denorm) / y_test_denorm)) * 100

        metrics = {
            'mse': mse,
            'rmse': rmse,
            'mae': mae,
            'mape': mape
        }

        print(f"   RMSE: {rmse:.2f}")
        print(f"   MAE: {mae:.2f}")
        print(f"   MAPE: {mape:.2f}%")

        return metrics

    def forecast(self, df: pd.DataFrame, periods=7):
        """
        äºˆæ¸¬å®Ÿè¡Œ

        Args:
            df: æœ€æ–°ãƒ‡ãƒ¼ã‚¿
            periods: äºˆæ¸¬æœŸé–“ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 7æ—¥ï¼‰

        Returns:
            dict: {
                'forecast': [äºˆæ¸¬å€¤ãƒªã‚¹ãƒˆ],
                'current_price': ç¾åœ¨ä¾¡æ ¼,
                'forecast_change': å¤‰åŒ–ç‡
            }
        """
        if self.model is None:
            raise ValueError("Model not trained. Call train() first.")

        print(f"\nğŸ”® Forecasting next {periods} days...")

        # æœ€æ–°ã®lookbackæ—¥åˆ†ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        recent_data = df[['open', 'high', 'low', 'close', 'volume']].tail(self.lookback).values

        # æ­£è¦åŒ–
        recent_data_normalized = self.scaler.transform(recent_data)

        # äºˆæ¸¬
        forecasts = []
        current_input = recent_data_normalized.copy()

        self.model.eval()
        with torch.no_grad():
            for _ in range(periods):
                # å…¥åŠ›ã‚’æº–å‚™
                X = torch.FloatTensor(current_input).unsqueeze(0).to(self.device)

                # äºˆæ¸¬
                pred = self.model(X).cpu().numpy()[0, 0]
                forecasts.append(pred)

                # æ¬¡ã®å…¥åŠ›ã‚’æº–å‚™ï¼ˆäºˆæ¸¬å€¤ã‚’ä½¿ã†ï¼‰
                # ç°¡æ˜“ç‰ˆ: closeã ã‘äºˆæ¸¬å€¤ã«ç½®ãæ›ãˆã€ä»–ã¯æœ€å¾Œã®å€¤ã‚’ä½¿ã†
                next_row = current_input[-1].copy()
                next_row[3] = pred  # closeä¾¡æ ¼ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã¯3

                # ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚’ã‚¹ãƒ©ã‚¤ãƒ‰
                current_input = np.vstack([current_input[1:], next_row])

        # é€†æ­£è¦åŒ–
        forecasts_denorm = self._denormalize_price(np.array(forecasts).reshape(-1, 1))

        current_price = df['close'].iloc[-1]
        final_forecast = forecasts_denorm[-1][0]
        forecast_change = ((final_forecast - current_price) / current_price) * 100

        print(f"   Current price: ${current_price:,.2f}")
        print(f"   Forecast ({periods}d): ${final_forecast:,.2f}")
        print(f"   Change: {forecast_change:+.2f}%")

        return {
            'forecast': forecasts_denorm.flatten().tolist(),
            'current_price': float(current_price),
            'forecast_price': float(final_forecast),
            'forecast_change': float(forecast_change)
        }

    def _denormalize_price(self, normalized_value):
        """
        æ­£è¦åŒ–ã•ã‚ŒãŸä¾¡æ ¼ã‚’å…ƒã®ã‚¹ã‚±ãƒ¼ãƒ«ã«æˆ»ã™

        Args:
            normalized_value: æ­£è¦åŒ–ã•ã‚ŒãŸå€¤

        Returns:
            å…ƒã®ã‚¹ã‚±ãƒ¼ãƒ«ã®å€¤
        """
        # closeã®åˆ—ã ã‘ã‚’é€†å¤‰æ›
        # scalerã¯5æ¬¡å…ƒã§å­¦ç¿’ã—ã¦ã„ã‚‹ã®ã§ã€ãƒ€ãƒŸãƒ¼ã‚’ä½œã‚‹
        dummy = np.zeros((len(normalized_value), 5))
        dummy[:, 3] = normalized_value.flatten()  # closeã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹

        denormalized = self.scaler.inverse_transform(dummy)
        return denormalized[:, 3].reshape(-1, 1)


def main():
    """ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')

    from src.data.timeseries_storage import TimeSeriesStorage

    storage = TimeSeriesStorage()
    engine = GRUForecastingEngine(lookback=60, forecast_horizon=7)

    # BTCã®1æ—¥è¶³ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
    df = storage.load_price_data('BTC', '1d')

    if df.empty or len(df) < 100:
        print("âŒ BTCã®ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™ï¼ˆæœ€ä½100æ—¥åˆ†å¿…è¦ï¼‰")
        return

    print("=" * 80)
    print("GRU Forecasting Engine Test")
    print("=" * 80)

    # ãƒ‡ãƒ¼ã‚¿æº–å‚™
    train_loader, val_loader, test_data = engine.prepare_data(df, train_ratio=0.8)

    # è¨“ç·´
    engine.train(train_loader, val_loader, epochs=100, learning_rate=0.001)

    # è©•ä¾¡
    metrics = engine.evaluate(test_data)

    # äºˆæ¸¬
    forecast_result = engine.forecast(df, periods=7)

    print("\n" + "=" * 80)
    print("Forecast Results")
    print("=" * 80)
    for i, price in enumerate(forecast_result['forecast'], 1):
        print(f"  Day {i}: ${price:,.2f}")

    print("\n" + "=" * 80)
    print(f"âœ… GRUå®Ÿè£…å®Œäº†ï¼MAPE: {metrics['mape']:.2f}%ï¼ˆç›®æ¨™: <0.5%ï¼‰")
    print("=" * 80)


if __name__ == '__main__':
    main()
