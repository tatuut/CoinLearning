"""
è©³ç´°ãƒ‡ãƒ¼ã‚¿åé›†ã‚·ã‚¹ãƒ†ãƒ 

WebSearchã®å…¨çµæœã€ä¾¡æ ¼ã®è©³ç´°å±¥æ­´ã€ã‚ªãƒ³ãƒã‚§ãƒ¼ãƒ³ãƒ‡ãƒ¼ã‚¿ãªã©
ã€Œæœ€ã‚‚è©³ç´°ãªãƒ‡ãƒ¼ã‚¿ã€ã‚’å–å¾—ãƒ»ä¿å­˜ã™ã‚‹
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.data.advanced_database import AdvancedDatabase
from src.config.exchange_api import MEXCAPI
from datetime import datetime, timedelta
import json
import sqlite3


class DetailedDataCollector:
    """è©³ç´°ãƒ‡ãƒ¼ã‚¿åé›†ã‚·ã‚¹ãƒ†ãƒ """

    def __init__(self):
        self.db = AdvancedDatabase()
        self.api = MEXCAPI()
        self._extend_tables()

    def _extend_tables(self):
        """ã‚ˆã‚Šè©³ç´°ãªãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã™ã‚‹ãŸã‚ã®ãƒ†ãƒ¼ãƒ–ãƒ«æ‹¡å¼µ"""
        cursor = self.db.conn.cursor()

        # 1. è©³ç´°ä¾¡æ ¼å±¥æ­´ãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆå…¨æœŸé–“ã®ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ï¼‰
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS price_history_detailed (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                symbol TEXT NOT NULL,
                timestamp INTEGER NOT NULL,
                interval TEXT NOT NULL,
                open REAL,
                high REAL,
                low REAL,
                close REAL,
                volume REAL,
                quote_volume REAL,
                trades_count INTEGER,
                taker_buy_volume REAL,
                taker_buy_quote_volume REAL,
                collected_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                UNIQUE(symbol, timestamp, interval)
            )
        ''')

        # 2. WebSearchç”Ÿãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆæ¤œç´¢çµæœã®å®Œå…¨ä¿å­˜ï¼‰
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS websearch_raw (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                search_query TEXT NOT NULL,
                search_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                result_index INTEGER,
                title TEXT,
                url TEXT,
                snippet TEXT,
                full_content TEXT,
                metadata_json TEXT,
                relevance_score REAL,
                source_domain TEXT,
                published_date TEXT,
                author TEXT,
                image_urls TEXT,
                related_links TEXT
            )
        ''')

        # 3. å¸‚å ´çµ±è¨ˆè©³ç´°ãƒ†ãƒ¼ãƒ–ãƒ«
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS market_stats_detailed (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                symbol TEXT NOT NULL,
                timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                price REAL,
                market_cap REAL,
                volume_24h REAL,
                volume_change_24h REAL,
                percent_change_1h REAL,
                percent_change_24h REAL,
                percent_change_7d REAL,
                percent_change_30d REAL,
                circulating_supply REAL,
                total_supply REAL,
                max_supply REAL,
                rank_by_marketcap INTEGER,
                dominance REAL,
                turnover_rate REAL,
                raw_data_json TEXT
            )
        ''')

        # 4. ã‚ªãƒ¼ãƒ€ãƒ¼ãƒ–ãƒƒã‚¯å±¥æ­´ï¼ˆæ¿æƒ…å ±ï¼‰
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS orderbook_history (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                symbol TEXT NOT NULL,
                timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                bids_json TEXT,
                asks_json TEXT,
                bid_depth_1pct REAL,
                ask_depth_1pct REAL,
                spread REAL,
                mid_price REAL
            )
        ''')

        # 5. ãƒ‹ãƒ¥ãƒ¼ã‚¹å…¨æ–‡ä¿å­˜ãƒ†ãƒ¼ãƒ–ãƒ«
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS news_full_text (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                news_id INTEGER,
                full_html TEXT,
                full_markdown TEXT,
                extracted_data TEXT,
                images_json TEXT,
                videos_json TEXT,
                related_articles_json TEXT,
                author_info TEXT,
                comment_count INTEGER,
                share_count INTEGER,
                fetched_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (news_id) REFERENCES news(id)
            )
        ''')

        self.db.conn.commit()

    def collect_price_history(self, symbol: str, interval: str = '1h',
                             days_back: int = 30, save_to_db: bool = True):
        """
        è©³ç´°ãªä¾¡æ ¼å±¥æ­´ã‚’åé›†

        Args:
            symbol: éŠ˜æŸ„ã‚·ãƒ³ãƒœãƒ«
            interval: æ™‚é–“è¶³ï¼ˆ1m, 5m, 15m, 30m, 1h, 4h, 1d, 1wï¼‰
            days_back: ä½•æ—¥åˆ†é¡ã‚‹ã‹
            save_to_db: DBã«ä¿å­˜ã™ã‚‹ã‹

        Returns:
            ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã®ãƒªã‚¹ãƒˆ
        """
        print(f"ğŸ“Š {symbol} ã®è©³ç´°ä¾¡æ ¼å±¥æ­´å–å¾—ä¸­...")
        print(f"   æœŸé–“: {days_back}æ—¥åˆ†")
        print(f"   é–“éš”: {interval}")

        # 1æ™‚é–“è¶³ã®å ´åˆã®å¿…è¦ãªãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆæ•°
        limit_map = {
            '1m': days_back * 24 * 60,
            '5m': days_back * 24 * 12,
            '15m': days_back * 24 * 4,
            '30m': days_back * 24 * 2,
            '1h': days_back * 24,
            '4h': days_back * 6,
            '1d': days_back,
            '1w': days_back // 7,
        }

        limit = min(limit_map.get(interval, 1000), 1000)  # MEXC APIã®ä¸Šé™

        try:
            klines = self.api.get_klines(f"{symbol}USDT", interval=interval, limit=limit)
            print(f"   âœ“ å–å¾—ä»¶æ•°: {len(klines)}ä»¶")

            if save_to_db:
                cursor = self.db.conn.cursor()
                saved_count = 0

                for kline in klines:
                    try:
                        cursor.execute('''
                            INSERT OR REPLACE INTO price_history_detailed
                            (symbol, timestamp, interval, open, high, low, close, volume, quote_volume)
                            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
                        ''', (
                            symbol,
                            kline['timestamp'],
                            interval,
                            float(kline['open']),
                            float(kline['high']),
                            float(kline['low']),
                            float(kline['close']),
                            float(kline['volume']),
                            float(kline.get('quote_volume', 0))
                        ))
                        saved_count += 1
                    except Exception as e:
                        print(f"   âœ— ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")

                self.db.conn.commit()
                print(f"   âœ“ DBä¿å­˜: {saved_count}ä»¶")

            return klines

        except Exception as e:
            print(f"   âœ— å–å¾—å¤±æ•—: {e}")
            return []

    def save_websearch_result(self, query: str, results: list):
        """
        WebSearchçµæœã‚’å®Œå…¨ä¿å­˜

        Args:
            query: æ¤œç´¢ã‚¯ã‚¨ãƒª
            results: WebSearchã®çµæœãƒªã‚¹ãƒˆ

        ä½¿ã„æ–¹:
            Claude Codeã§WebSearchã‚’å®Ÿè¡Œå¾Œã€çµæœã‚’ã“ã®ãƒ¡ã‚½ãƒƒãƒ‰ã«æ¸¡ã™
        """
        print(f"ğŸ” WebSearchçµæœã‚’è©³ç´°ä¿å­˜ä¸­...")
        print(f"   ã‚¯ã‚¨ãƒª: {query}")
        print(f"   çµæœæ•°: {len(results)}ä»¶")

        cursor = self.db.conn.cursor()
        saved_count = 0

        for i, result in enumerate(results):
            try:
                cursor.execute('''
                    INSERT INTO websearch_raw
                    (search_query, result_index, title, url, snippet,
                     full_content, metadata_json, source_domain)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?)
                ''', (
                    query,
                    i,
                    result.get('title', ''),
                    result.get('url', ''),
                    result.get('snippet', ''),
                    result.get('content', ''),
                    json.dumps(result.get('metadata', {}), ensure_ascii=False),
                    result.get('domain', '')
                ))
                saved_count += 1
            except Exception as e:
                print(f"   âœ— ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")

        self.db.conn.commit()
        print(f"   âœ“ ä¿å­˜å®Œäº†: {saved_count}ä»¶")

    def collect_market_stats(self, symbol: str, save_to_db: bool = True):
        """
        è©³ç´°ãªå¸‚å ´çµ±è¨ˆã‚’åé›†

        ç¾åœ¨ä¾¡æ ¼ã ã‘ã§ãªãã€æ™‚ä¾¡ç·é¡ã€ä¾›çµ¦é‡ã€ãƒ©ãƒ³ã‚­ãƒ³ã‚°ãªã©ã‚‚ä¿å­˜
        """
        print(f"ğŸ“ˆ {symbol} ã®è©³ç´°å¸‚å ´çµ±è¨ˆå–å¾—ä¸­...")

        try:
            # 24hçµ±è¨ˆ
            stats = self.api.get_24h_stats(f"{symbol}USDT")

            if save_to_db:
                cursor = self.db.conn.cursor()
                cursor.execute('''
                    INSERT INTO market_stats_detailed
                    (symbol, price, volume_24h, percent_change_24h, raw_data_json)
                    VALUES (?, ?, ?, ?, ?)
                ''', (
                    symbol,
                    stats.get('price', 0),
                    stats.get('volume', 0),
                    stats.get('price_change_percent', 0),
                    json.dumps(stats, ensure_ascii=False)
                ))
                self.db.conn.commit()
                print(f"   âœ“ çµ±è¨ˆä¿å­˜å®Œäº†")

            return stats

        except Exception as e:
            print(f"   âœ— å–å¾—å¤±æ•—: {e}")
            return None

    def get_price_analysis(self, symbol: str, interval: str = '1h', limit: int = 100):
        """
        ä¿å­˜ã•ã‚ŒãŸè©³ç´°ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰åˆ†ææƒ…å ±ã‚’å–å¾—

        Returns:
            åˆ†æçµæœã®è¾æ›¸
        """
        cursor = self.db.conn.cursor()

        cursor.execute('''
            SELECT timestamp, open, high, low, close, volume
            FROM price_history_detailed
            WHERE symbol = ? AND interval = ?
            ORDER BY timestamp DESC
            LIMIT ?
        ''', (symbol, interval, limit))

        rows = cursor.fetchall()

        if not rows:
            return None

        prices = [row[4] for row in rows]  # close price
        volumes = [row[5] for row in rows]

        analysis = {
            'data_points': len(rows),
            'current_price': prices[0],
            'average_price': sum(prices) / len(prices),
            'max_price': max(prices),
            'min_price': min(prices),
            'price_range': max(prices) - min(prices),
            'average_volume': sum(volumes) / len(volumes),
            'total_volume': sum(volumes),
            'volatility': (max(prices) - min(prices)) / min(prices) * 100,
            'trend': 'UP' if prices[0] > prices[-1] else 'DOWN',
            'period_change': ((prices[0] - prices[-1]) / prices[-1]) * 100,
        }

        return analysis

    def export_detailed_data(self, symbol: str, output_file: str = None):
        """
        éŠ˜æŸ„ã®å…¨è©³ç´°ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ

        Args:
            symbol: éŠ˜æŸ„ã‚·ãƒ³ãƒœãƒ«
            output_file: å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åï¼ˆNoneã®å ´åˆã¯è‡ªå‹•ç”Ÿæˆï¼‰

        Returns:
            ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã®è¾æ›¸
        """
        print(f"ğŸ“¦ {symbol} ã®å…¨è©³ç´°ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆä¸­...")

        cursor = self.db.conn.cursor()

        # 1. ä¾¡æ ¼å±¥æ­´
        cursor.execute('''
            SELECT * FROM price_history_detailed
            WHERE symbol = ?
            ORDER BY timestamp DESC
        ''', (symbol,))
        price_data = [dict(row) for row in cursor.fetchall()]

        # 2. ãƒ‹ãƒ¥ãƒ¼ã‚¹
        cursor.execute('''
            SELECT * FROM news
            WHERE symbol = ?
            ORDER BY published_date DESC
        ''', (symbol,))
        news_data = [dict(row) for row in cursor.fetchall()]

        # 3. å¸‚å ´çµ±è¨ˆ
        cursor.execute('''
            SELECT * FROM market_stats_detailed
            WHERE symbol = ?
            ORDER BY timestamp DESC
        ''', (symbol,))
        stats_data = [dict(row) for row in cursor.fetchall()]

        export_data = {
            'symbol': symbol,
            'export_date': datetime.now().isoformat(),
            'price_history': price_data,
            'news': news_data,
            'market_stats': stats_data,
            'summary': {
                'price_data_points': len(price_data),
                'news_count': len(news_data),
                'stats_snapshots': len(stats_data),
            }
        }

        # ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        if output_file is None:
            output_file = f"data_export_{symbol}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"

        output_path = os.path.join(os.path.dirname(__file__), '..', 'exports', output_file)
        os.makedirs(os.path.dirname(output_path), exist_ok=True)

        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(export_data, f, ensure_ascii=False, indent=2, default=str)

        print(f"   âœ“ ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå®Œäº†: {output_path}")
        print(f"   ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿: {len(price_data)}ä»¶")
        print(f"   ãƒ‹ãƒ¥ãƒ¼ã‚¹: {len(news_data)}ä»¶")
        print(f"   å¸‚å ´çµ±è¨ˆ: {len(stats_data)}ä»¶")

        return export_data

    def close(self):
        """ãƒªã‚½ãƒ¼ã‚¹ã‚’ã‚¯ãƒ­ãƒ¼ã‚º"""
        self.db.close()


def main():
    """ä½¿ç”¨ä¾‹"""
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')

    import argparse

    parser = argparse.ArgumentParser(
        description='è©³ç´°ãƒ‡ãƒ¼ã‚¿åé›†ãƒ„ãƒ¼ãƒ«',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ä¾‹:
  # BTCã®1æ™‚é–“è¶³ãƒ‡ãƒ¼ã‚¿ã‚’30æ—¥åˆ†åé›†
  python detailed_data_collector.py BTC --interval 1h --days 30

  # BTCã®è©³ç´°ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
  python detailed_data_collector.py BTC --export

  # è¤‡æ•°ã®æ™‚é–“è¶³ã‚’ä¸€æ‹¬åé›†
  python detailed_data_collector.py BTC --all-intervals

åé›†ã•ã‚Œã‚‹ãƒ‡ãƒ¼ã‚¿:
  - ä¾¡æ ¼å±¥æ­´ï¼ˆ1m, 5m, 15m, 30m, 1h, 4h, 1dï¼‰
  - å¸‚å ´çµ±è¨ˆï¼ˆæ™‚ä¾¡ç·é¡ã€ä¾›çµ¦é‡ã€ãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼‰
  - WebSearchçµæœã®å®Œå…¨ä¿å­˜
  - ã‚ªãƒ¼ãƒ€ãƒ¼ãƒ–ãƒƒã‚¯å±¥æ­´ï¼ˆå®Ÿè£…äºˆå®šï¼‰
        """
    )

    parser.add_argument('symbol', help='éŠ˜æŸ„ã‚·ãƒ³ãƒœãƒ«ï¼ˆä¾‹: BTCï¼‰')
    parser.add_argument('--interval', default='1h',
                       help='æ™‚é–“è¶³ï¼ˆ1m, 5m, 15m, 30m, 1h, 4h, 1dï¼‰')
    parser.add_argument('--days', type=int, default=30,
                       help='åé›†ã™ã‚‹æ—¥æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 30ï¼‰')
    parser.add_argument('--all-intervals', action='store_true',
                       help='å…¨ã¦ã®æ™‚é–“è¶³ã‚’åé›†')
    parser.add_argument('--export', action='store_true',
                       help='å…¨ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ')
    parser.add_argument('--stats', action='store_true',
                       help='å¸‚å ´çµ±è¨ˆã‚’åé›†')

    args = parser.parse_args()

    collector = DetailedDataCollector()

    try:
        symbol = args.symbol.upper()

        if args.export:
            # å…¨ãƒ‡ãƒ¼ã‚¿ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
            collector.export_detailed_data(symbol)

        elif args.all_intervals:
            # å…¨æ™‚é–“è¶³ã‚’åé›†
            intervals = ['1h', '4h', '1d']
            for interval in intervals:
                print()
                collector.collect_price_history(symbol, interval=interval, days_back=args.days)

        else:
            # æŒ‡å®šã•ã‚ŒãŸæ™‚é–“è¶³ã‚’åé›†
            collector.collect_price_history(symbol, interval=args.interval, days_back=args.days)

        if args.stats:
            print()
            collector.collect_market_stats(symbol)

        # åˆ†æçµæœè¡¨ç¤º
        print()
        print("="*80)
        print(f"ğŸ“Š {symbol} - ä¿å­˜ãƒ‡ãƒ¼ã‚¿åˆ†æ")
        print("="*80)

        for interval in ['1h', '4h', '1d']:
            analysis = collector.get_price_analysis(symbol, interval=interval)
            if analysis:
                print(f"\nã€{interval}è¶³ã€‘")
                print(f"  ãƒ‡ãƒ¼ã‚¿æ•°: {analysis['data_points']}ä»¶")
                print(f"  ç¾åœ¨ä¾¡æ ¼: ${analysis['current_price']:,.2f}")
                print(f"  å¹³å‡ä¾¡æ ¼: ${analysis['average_price']:,.2f}")
                print(f"  å¤‰å‹•å¹…: ${analysis['price_range']:,.2f} ({analysis['volatility']:.2f}%)")
                print(f"  ãƒˆãƒ¬ãƒ³ãƒ‰: {analysis['trend']} ({analysis['period_change']:+.2f}%)")

    finally:
        collector.close()


if __name__ == '__main__':
    main()
